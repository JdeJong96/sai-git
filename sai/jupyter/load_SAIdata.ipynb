{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f910d0a-62ea-4477-b688-781da970f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc6ed9f-e885-427b-9923-ba84ace1ed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_mfdataset(filepaths: str,list[str], ncstore_dir: str='~/kerchunk', **kwargs):\n",
    "    \"\"\"a faster alternative to xr.open_mfdataset using kerchunk\n",
    "    \n",
    "    This function uses kerchunk to create an NC_STORE reference file,\n",
    "    that instructs the program how to read the netCDF files efficiently. \n",
    "    Coordinates must be consistent throughout all files.\n",
    "    The NC_STORE is saved after first use, and will be read on each \n",
    "    subsequent usage of this function.\n",
    "    \n",
    "    Parameters:\n",
    "    filepaths : str or list[str]\n",
    "        (list of) netCDF file names, may contain wild cards\n",
    "    ncstore_dir: Pathlike\n",
    "        Path where NC_STORE reference files will be saved\n",
    "    kwargs: dict\n",
    "        any additional keyword arguments are passed on to xr.open_dataset\n",
    "        \n",
    "    Returns: xr.Dataset\n",
    "        a Dataset instance containing all the netCDF data\n",
    "        \n",
    "    v0.0\n",
    "    \"\"\"\n",
    "    \n",
    "    # make sorted list of absolute filepaths\n",
    "    if isinstance(filepaths, str):\n",
    "        filepaths = glob.glob(filepaths)\n",
    "    filepaths = sorted([os.path.abspath(fp) for fp in filepaths])\n",
    "    if len(filepaths) == 1: # use xr.open_dataset directly if there is one file\n",
    "        return xr.open_dataset(filepaths[0], **kwargs)\n",
    "    \n",
    "    # set default keyword arguments for xr.open_dataset on NC_STORE file\n",
    "    default_kw = {'engine':'kerchunk', 'storage_options':{'target_protocol':'file'}}\n",
    "    for (k,v) in default_kw.items():\n",
    "        if k in kwargs:\n",
    "            print(f'open_mfdataset(): ignoring keyword {k}')\n",
    "        kwargs[k] = v\n",
    "    \n",
    "    # create NC_STORE filename from netCDF filename, including timestamp\n",
    "    # of first and last file. Open and return dataset if the file already exists\n",
    "    ncstore_dir = os.path.expanduser(ncstore_dir)\n",
    "    timestr = lambda i: os.path.basename(filepaths[i]).split('.')[-2] # timestamp\n",
    "    ncstorefile = (os.path.basename(filepaths[0])\n",
    "                   .replace(timestr(0),f\"{timestr(0)}_{timestr(-1)}\")\n",
    "                   .replace('.nc','.json'))\n",
    "    ncstore_path = os.path.join(ncstore_dir, ncstorefile)\n",
    "    if not os.path.exists(ncstore_dir):\n",
    "        os.mkdir(ncstore_dir)\n",
    "    elif os.path.exists(ncstore_path):\n",
    "        print(f\"Reading combined kerchunk reference file {ncstore_path}\")\n",
    "        return xr.open_dataset(ncstore_path, **kwargs)\n",
    "    \n",
    "    # make new NC_STORE data\n",
    "    filebag = dask.bag.from_sequence(filepaths, npartitions=None)\n",
    "    reffiles = (filebag.map(NetCDF3ToZarr, inline_threshold=0, max_chunk_size=0)\n",
    "                .map(lambda z: z.translate()).compute())\n",
    "    mzz = MultiZarrToZarr(reffiles, concat_dims=['time'], coo_map={'time':'cf:time'})\n",
    "    \n",
    "    # write NC_STORE data and return opened dataset\n",
    "    with open(f\"{ncstore_path}\", \"wb\") as f:\n",
    "       print(f\"Writing combined kerchunk reference file {ncstore_path}\")\n",
    "       f.write(json.dumps(mzz.translate()).encode())\n",
    "    \n",
    "    return xr.open_dataset(ncstore_path, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "88df8e49-2b7e-4d56-bc1a-8b6695f71417",
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = ['cam2','pop','clm2','cice']\n",
    "cases = {\n",
    "    'lres.spinup':'spinup_pd_maxcores_f09_g16', # 200-300 => 2000-2100\n",
    "    'lres.sai20':'lres_b.e10.B2000_CAM5.f09_g16.feedforward.001',\n",
    "    'lres.sai':'lres_b.e10.B2000_CAM5.f09_g16.feedforward_2050.001',\n",
    "    'mres.cnt':'rcp8.5_co2_f05_t12', # 2000-2100\n",
    "    'mres.sai':'mres_b.e10.B2000_CAM5.f05_t12.001', # 2045-2100\n",
    "    'hres.ref.1':'b.e10.B_RCP8.5_CO2_CAM5.f02_t12.started_2002-12.001',\n",
    "    'hres.ref.2':'b.e10.B_RCP8.5_CO2_CAM5.f02_t12.started_2002-12.002',\n",
    "    'hres.ref.3':'b.e10.B_RCP8.5_CO2_CAM5.f02_t12.started_2002-12.003',\n",
    "    'hres.ref.4':'b.e10.B_RCP8.5_CO2_CAM5.f02_t12.started_2002-12.004',\n",
    "    'hres.ref.5':'b.e10.B_RCP8.5_CO2_CAM5.f02_t12.started_2002-12.005',\n",
    "    'hres.ref.6':'hres_b.e10.B2000_CAM5.f02_t12.started_2002-12_without_SAI.001', # additional run with 6hrly 3D output\n",
    "    'hres.cnt.1':'b.e10.B_RCP8.5_CO2_CAM5.f02_t12.started_2092-12.001',\n",
    "    'hres.cnt.2':'b.e10.B_RCP8.5_CO2_CAM5.f02_t12.started_2092-12.002',\n",
    "    'hres.cnt.3':'b.e10.B_RCP8.5_CO2_CAM5.f02_t12.started_2092-12.003',\n",
    "    'hres.cnt.4':'b.e10.B_RCP8.5_CO2_CAM5.f02_t12.started_2092-12.004',\n",
    "    'hres.cnt.5':'b.e10.B_RCP8.5_CO2_CAM5.f02_t12.started_2092-12.005',\n",
    "    'hres.cnt.6':'hres_b.e10.B2000_CAM5.f02_t12.started_2092-12_without_SAI.001', # additional run with 6hrly 3D output\n",
    "    'hres.sai.1':'hres_b.e10.B2000_CAM5.f02_t12.started_2092-12.001',\n",
    "    'hres.sai.2':'hres_b.e10.B2000_CAM5.f02_t12.started_2092-12.002',\n",
    "    'hres.sai.3':'hres_b.e10.B2000_CAM5.f02_t12.started_2092-12.003',\n",
    "    'hres.sai.4':'hres_b.e10.B2000_CAM5.f02_t12.started_2092-12.004',\n",
    "    'hres.sai.5':'hres_b.e10.B2000_CAM5.f02_t12.started_2092-12.005',\n",
    "    'hres.sai.6':'hres_b.e10.B2000_CAM5.f02_t12.started_2092-12.006', # additional run with 6hrly 3D output\n",
    "}\n",
    "\n",
    "def get_casedir(tag):\n",
    "    '''returns full path to the case directory given a case tag'''\n",
    "    if tag not in cases:\n",
    "        raise KeyError(f'tag ({tag}) not found in {cases.keys()}')\n",
    "    grid = {'lres':'f09_g16', 'mres':'f05_t12', 'hres':'f02_t12'}[tag.split('.')[0]]\n",
    "    isInNWO = (tag.split('.')[1] in ['sai','sai20']) or (tag in ['hres.ref.6','hres.cnt.6'])\n",
    "    root = ('/projects/0/nwo2021025/archive' if isInNWO else\n",
    "            f'/projects/0/prace_imau/prace_2013081679/cesm1_0_4/{grid}')\n",
    "    addOUTPUT = (not isInNWO) and (tag != 'mres.cnt')\n",
    "    casedir = f'{root}/{cases[tag]}' + ('/OUTPUT' if addOUTPUT else '')\n",
    "    return casedir\n",
    "\n",
    "\n",
    "def print_compstream(tag):\n",
    "    '''returns available file streams for each model component given a case tag'''\n",
    "    casedir = get_casedir(tag)\n",
    "    ncFiles = sorted([file for dirs in os.walk(top=casedir) for file in dirs[2] if file.endswith('.nc')])\n",
    "    for comp in comps:\n",
    "        compfiles = [file for file in ncFiles if comp in file.split('.')]\n",
    "        compids = [file.split('.').index(comp) for file in compfiles]\n",
    "        comp_available_streams = np.sort(np.unique([file.split('.')[id+1] for file,id in zip(compfiles,compids)]))\n",
    "        print(f\"{comp}: {comp_available_streams}\", end=\", \")\n",
    "    print()\n",
    "\n",
    "\n",
    "def select_compstream(tag, comp, stream):\n",
    "    '''return all files for a given model component comp and file stream'''\n",
    "    casedir = get_casedir(tag)\n",
    "    ncFiles = sorted([file for dirs in os.walk(top=casedir) for file in dirs[2] if file.endswith('.nc')])\n",
    "    return np.sort([file for file in ncFiles if (comp in file.split('.')) and (stream in file.split('.'))])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed933315-1506-42a3-ab08-62185f997d16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
